//@version=6
library("LogisticTrainingUtils", overlay=false)

import jonathanmoletta17/LogisticRegressionUtils/3 as lr

// Result object returned by the training function
export type TrainResult
    float w0
    float w1
    float w2
    float loss

// -----------------------------------------------------------------------------
// gradientDescent
// Executes simple gradient descent on the logistic regression model.
//   - x1, x2: feature arrays for each sample
//   - y:      target array (1 for valid pivot, 0 for broken pivot)
//   - rate:   learning rate
//   - epochs: number of optimization iterations
// Returns a TrainResult with the final weights and average loss.
// -----------------------------------------------------------------------------
export gradientDescent(float[] x1, float[] x2, float[] y, float rate, int epochs) =>
    int n = math.min(array.size(x1), math.min(array.size(x2), array.size(y)))
    float w0 = 0.0
    float w1 = 0.0
    float w2 = 0.0
    float loss = na
    for ep = 0 to epochs - 1
        float epochLoss = 0.0
        for i = 0 to n - 1
            float f1 = array.get(x1, i)
            float f2 = array.get(x2, i)
            float label = array.get(y, i)
            float pred = lr.logistic(f1, f2, w0, w1, w2)
            float error = pred - label
            w0 -= rate * error
            w1 -= rate * error * f1
            w2 -= rate * error * f2
            epochLoss += lr.logLoss(label, pred)
        if n > 0
            epochLoss /= n
        loss := epochLoss
    TrainResult.new(w0, w1, w2, loss)